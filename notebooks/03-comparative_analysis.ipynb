{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4885fd03-686f-492c-92bd-c6a363b9d3bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8afd6c8-6bbf-4702-866f-f78c76ae80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV,cross_val_score,KFold,ShuffleSplit,cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report,roc_auc_score,roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import  Markdown\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8508683-6a38-43a8-918a-4660d69a3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6ccc9-722b-41da-890e-99f07b94a6a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc75079-0452-4c7c-89f9-fc4ec2fca6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/interim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7904bcf-2a8c-4940-a716-5314db8084d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_score_v2(data_X,data_Y,data_name,estimator,estimator_name,estimator_params):\n",
    "    scores = [\"recall\",\"accuracy\",\"f1\"]\n",
    "    print(\"data name: \", data_name)\n",
    "    \n",
    "    print(\"model name: \",estimator_name)\n",
    "    \n",
    "    model_gs = BayesSearchCV(estimator, search_spaces=estimator_params, scoring='accuracy')\n",
    "\n",
    "    results = cross_validate(model_gs,data_X,data_Y, scoring=scores, cv=ShuffleSplit(n_splits=3, test_size=0.2, random_state=42))\n",
    "    results[\"model_name\"] = [f\"{estimator_name}-{data_name}\"] * len(results[\"score_time\"])\n",
    "    \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e9ec47-a785-4689-a3ac-7d20a87785f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modificar\n",
    "def build_score(y_pred,y_true,probs):\n",
    "    print(\"Acuracia : {}%\".format(round(accuracy_score(y_pred=y_pred,y_true=y_true)*100,3)))\n",
    "    print(\"F1_score: {}%\".format(round(f1_score(y_pred=y_pred,y_true=y_true)*100,3)))\n",
    "    print(\"Precison: {}%\".format(round(precision_score(y_pred=y_pred,y_true=y_true)*100,3)))\n",
    "    print(\"Recall: {}%\".format(round(recall_score(y_pred=y_pred,y_true=y_true)*100,3)))\n",
    "    print(\"-\"*20)\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test,y_pred,target_names=[\"FAKE\",\"TRUE\"]))\n",
    "    print(\"-\"*20)\n",
    "    print(\"Plot curva roc\")\n",
    "    lr_auc = roc_auc_score(y_true, probs[:, 1])\n",
    "    print('ROC AUC=%.3f' % (lr_auc))\n",
    "    fpr, tpr, _ = roc_curve(y_true, probs[:, 1])\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24373749-3d36-49c6-b343-8f84a48ba624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "    result = [''] * len(s.values)\n",
    "    if s.values[0].endswith('time'):\n",
    "        result[np.argmin(values)+1] = props\n",
    "    else:\n",
    "        result[np.argmax(values)+1] = props\n",
    "    return result\n",
    "\n",
    "def get_winner(s):\n",
    "    metric = s.values[0]\n",
    "    values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "    models = results.columns[1:]\n",
    "    \n",
    "    if s.values[0].endswith('time'):\n",
    "        return models[np.argmin(values)]\n",
    "    else:\n",
    "        return models[np.argmax(values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b16e93-6185-4162-9dea-7f7d82cabd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\n",
    "        \"RF\",\n",
    "        RandomForestClassifier(),\n",
    "        {\n",
    "            \"n_estimators\": [300,800,1200],\n",
    "            \"max_depth\": [5, 8, 15, 25],\n",
    "            \"max_features\":['log2', 'sqrt']\n",
    "        }\n",
    "    ),\n",
    "    ( \n",
    "        \"LR\",\n",
    "        LogisticRegression(solver='liblinear', max_iter=10000),\n",
    "        {\n",
    "            \"penalty\": ['l1', 'l2'],\n",
    "            \"C\":[0.001,0.01,0.1,1]\n",
    "        }\n",
    "    ),\n",
    "     (\n",
    "         \"Tree\",\n",
    "          DecisionTreeClassifier(),\n",
    "         {\n",
    "            'criterion' : ['gini', 'entropy'],\n",
    "            'max_depth' : [6,8,10,12],\n",
    "            'max_features':[2,4,6,8]\n",
    "\n",
    "         }\n",
    "     ),\n",
    "     (\n",
    "         \"ADA\" ,\n",
    "         AdaBoostClassifier(),\n",
    "         {\n",
    "            'n_estimators':[500,800,1200], \n",
    "            'learning_rate':[0.001, 0.01, 0.1, 1]\n",
    "         }\n",
    "     )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249489f1-0d45-4333-bb18-cc1c917b1ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10c07e79-42a2-4d0a-8742-914faf60657e",
   "metadata": {},
   "source": [
    "Rodar e guardar o resultado de cada dado separado, modificar amanhã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26321a7f-83a7-4fb6-aa8e-ab8bf5eb8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para comprar os modelos\n",
    "def compara_modelos(datasets:list, estimators:list):\n",
    "    # compara os modelos por dataset, já tunando os hyperparametros compara o melhor com melhor\n",
    "    results={}\n",
    "    for data_name,data_path in datasets:\n",
    "        vetorizar = TfidfVectorizer(lowercase=False, max_features=200)#mex_features -> 300\n",
    "        df = pd.read_csv(data_path)\n",
    "        # dividir dataset para validar o modelo após o treino.\n",
    "        bag_of_words_ = vetorizar.fit_transform(df[\"text\"])\n",
    "        X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "        y = df[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "        for estimator_name, estimator_obj, estimator_params in estimators:\n",
    "\n",
    "            model_results = cross_score_v2(X,y,data_name,estimator_obj,estimator_name,estimator_params)\n",
    "            if results:\n",
    "                for key, value in model_results.items():\n",
    "                    results[key] = np.append(results[key], value)\n",
    "            else:\n",
    "                results = model_results\n",
    "                \n",
    "                \n",
    "    #guarda o resultado da comparação\n",
    "    df_results = pd.DataFrame(results)\n",
    "    results = (\n",
    "        pd\n",
    "        .DataFrame(df_results)\n",
    "        .groupby(['model_name'])\n",
    "        .agg([lambda x: f\"{np.mean(x):.3f} ± {np.std(x):.3f}\"])\n",
    "        .transpose()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_0\": \"score\"})\n",
    "        .drop(columns=\"level_1\")\n",
    "            # .set_index('score')\n",
    "    )\n",
    "    # estiliza o dataframe deixando em cinza o melhor modelo\n",
    "    time_scores = ['fit_time', 'score_time']\n",
    "    winner = results.query('score not in @time_scores').apply(get_winner, axis=1).value_counts().index[0]\n",
    "    results.columns.name = ''\n",
    "    results = (\n",
    "        results\n",
    "        .style\n",
    "        .hide(axis='index')\n",
    "        .apply(highlight_max, props='color:white;background-color:gray', axis=1)\n",
    "    )\n",
    "    display(results)\n",
    "    display(Markdown(f'O melhor modelo é o : **{winner}**'))\n",
    "    # escolhe o melhor modelo\n",
    "    model_winner = winner.split(\"-\")[0]\n",
    "    data_winner= winner.split(\"-\")[1]\n",
    "    model_name, model, model_params  = [foo for foo in estimators if foo[0] == model_winner][0]\n",
    "    data_name, data_path  = [foo for foo in datasets if foo[0] == data_winner][0]\n",
    "    \n",
    "    # treina o melhor modelo com todos os textos\n",
    "    vetorizar = TfidfVectorizer(lowercase=False, max_features=200)\n",
    "    df = pd.read_csv(data_path)\n",
    "    bag_of_words_ = vetorizar.fit_transform(df[\"text\"])\n",
    "    X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "    y = df[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "    \n",
    "    # tuna os hyperparametros do melhor modelo\n",
    "    model_BS = BayesSearchCV(model, search_spaces=model_params, scoring='accuracy')\n",
    "    model_BS.fit(X, y)\n",
    "    \n",
    "    # Salvando modelo treinado\n",
    "    path =  f\"../models/model_{model.__class__.__name__}_{data_name}.joblib\"\n",
    "    joblib.dump(model_BS,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718a741-d900-4408-928a-756816367c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cdfad9-e6e7-4b0a-954b-e6520d02e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data name:  no_stop_words_lemma\n",
      "model name:  RF\n",
      "data name:  no_stop_words_lemma\n",
      "model name:  LR\n",
      "data name:  no_stop_words_lemma\n",
      "model name:  Tree\n",
      "data name:  no_stop_words_lemma\n",
      "model name:  ADA\n"
     ]
    }
   ],
   "source": [
    "datasets_lemma = [\n",
    "    (\"no_stop_words_lemma\",\"../data/interim/no_stopWords_lemma.csv\"),\n",
    "    (\"with_stop_words_lemma\",\"../data/interim/with_stopWords_lemma.csv\")\n",
    "]\n",
    "\n",
    "datasets_stemma = [\n",
    "    (\"no_stop_words_stemma\",\"../data/interim/no_stopWords_stemma.csv\"),\n",
    "    (\"with_stop_words_stemma\",\"../data/interim/with_stopWords_stemma.csv\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436f8ac-f0a1-49cf-80f7-1a11eb6575c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d864ee-dcc0-4b73-a11c-aefa71c3466f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe5ed9-c614-48f2-a7e8-73f09eb7439c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059edeaf-3d93-464e-af57-e126df9fe654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb78b2-9f7b-4711-9130-a5706a4e48ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5011365-9c41-4d3c-8e5b-cc508d503a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf497a6-3e5c-4030-b88c-8015788f2d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e26c5e-c7bf-4c27-9d20-1580ed15b70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f60ca7f-2466-4bea-9008-c3a519671ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38760faa-b079-4791-8271-8cc56a8a77fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eeb0ce1-0fdf-4b5c-af32-8ca7ff8d8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results={}\n",
    "# for data_name,data_path in datasets:\n",
    "#     vetorizar = TfidfVectorizer(lowercase=False, max_features=200)#mex_features -> 300\n",
    "#     df = pd.read_csv(data_path)\n",
    "#     bag_of_words_ = vetorizar.fit_transform(df[\"text\"])\n",
    "#     X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "#     y = df[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "#     for estimator_name, estimator_obj, estimator_params in estimators:\n",
    "\n",
    "#         model_results = cross_score_v2(X,y,data_name,estimator_obj,estimator_name,estimator_params)\n",
    "#         if results:\n",
    "#             for key, value in model_results.items():\n",
    "#                 results[key] = np.append(results[key], value)\n",
    "#         else:\n",
    "#             results = model_results\n",
    "\n",
    "\n",
    "# df_results = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "# results = (\n",
    "#     pd\n",
    "#     .DataFrame(df_results)\n",
    "#     .groupby(['model_name'])\n",
    "#     .agg([lambda x: f\"{np.mean(x):.3f} ± {np.std(x):.3f}\"])#\n",
    "#     .transpose()\n",
    "#     .reset_index()\n",
    "#     .rename(columns={\"level_0\": \"score\"})\n",
    "#     .drop(columns=\"level_1\")\n",
    "#     # .set_index('score')\n",
    "# )\n",
    "# time_scores = ['fit_time', 'score_time']\n",
    "# winner = results.query('score not in @time_scores').apply(get_winner, axis=1).value_counts().index[0]\n",
    "# results.columns.name = ''\n",
    "# results = (\n",
    "#     results\n",
    "#     .style\n",
    "#     .hide(axis='index')\n",
    "#     .apply(highlight_max, props='color:white;background-color:gray', axis=1)\n",
    "# )\n",
    "# display(results)\n",
    "# display(Markdown(f'O melhor modelo é o : **{winner}**'))\n",
    "\n",
    "\n",
    "\n",
    "# # Realizando treino do modelo completo\n",
    "# model_winner = winner.split(\"-\")[0]\n",
    "# data_winner= winner.split(\"-\")[1]\n",
    "# model_name, model, model_params  = [foo for foo in estimators if foo[0] == model_winner][0]\n",
    "# data_name, data_path  = [foo for foo in datasets if foo[0] == data_winner][0]\n",
    "\n",
    "# vetorizar = TfidfVectorizer(lowercase=False, max_features=50)\n",
    "# df = pd.read_csv(data_path)\n",
    "# bag_of_words_ = vetorizar.fit_transform(df[\"text\"])\n",
    "# X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "# y = df[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "\n",
    "# model_gs = GridSearchCV(model, model_params, scoring='accuracy')\n",
    "# model_gs.fit(X, y)\n",
    "\n",
    "\n",
    "# # Salvando modelo treinado\n",
    "# joblib.dump(model_gs, '../models/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4326e5-ec4e-4e42-a7bb-3c22316a83f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
