{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4885fd03-686f-492c-92bd-c6a363b9d3bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8afd6c8-6bbf-4702-866f-f78c76ae80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV,cross_val_score,KFold,ShuffleSplit,cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report,roc_auc_score,roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import  Markdown\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8508683-6a38-43a8-918a-4660d69a3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6ccc9-722b-41da-890e-99f07b94a6a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc75079-0452-4c7c-89f9-fc4ec2fca6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/interim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7904bcf-2a8c-4940-a716-5314db8084d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_score_v2(data_X,data_Y,data_name,estimator,estimator_name,estimator_params):\n",
    "    scores = [\"recall\",\"accuracy\",\"f1\"]\n",
    "    print(\"data name: \", data_name)\n",
    "    \n",
    "    print(\"model name: \",estimator_name)\n",
    "    \n",
    "    model_gs = BayesSearchCV(estimator, search_spaces=estimator_params, scoring='accuracy')\n",
    "\n",
    "    results = cross_validate(model_gs,data_X,data_Y, scoring=scores, cv=ShuffleSplit(n_splits=3, test_size=0.2, random_state=42))\n",
    "    results[\"model_name\"] = [f\"{estimator_name}-{data_name}\"] * len(results[\"score_time\"])\n",
    "    \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e9ec47-a785-4689-a3ac-7d20a87785f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modificar\n",
    "def build_score(y_pred,y_true,probs):\n",
    "    print(\"Acuracia : {}%\".format(round(accuracy_score(y_pred=y_pred,y_true=y_true)*100,3)))\n",
    "    print(\"F1_score: {}%\".format(round(f1_score(y_pred=y_pred,y_true=y_true)*100,3)))\n",
    "    print(\"Precison: {}%\".format(round(precision_score(y_pred=y_pred,y_true=y_true)*100,3)))\n",
    "    print(\"Recall: {}%\".format(round(recall_score(y_pred=y_pred,y_true=y_true)*100,3)))\n",
    "    print(\"-\"*20)\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test,y_pred,target_names=[\"FAKE\",\"TRUE\"]))\n",
    "    print(\"-\"*20)\n",
    "    print(\"Plot curva roc\")\n",
    "    lr_auc = roc_auc_score(y_true, probs[:, 1])\n",
    "    print('ROC AUC=%.3f' % (lr_auc))\n",
    "    fpr, tpr, _ = roc_curve(y_true, probs[:, 1])\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24373749-3d36-49c6-b343-8f84a48ba624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "    result = [''] * len(s.values)\n",
    "    if s.values[0].endswith('time'):\n",
    "        result[np.argmin(values)+1] = props\n",
    "    else:\n",
    "        result[np.argmax(values)+1] = props\n",
    "    return result\n",
    "\n",
    "def get_winner(s):\n",
    "    metric = s.values[0]\n",
    "    values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "    models = results.columns[1:]\n",
    "    \n",
    "    if s.values[0].endswith('time'):\n",
    "        return models[np.argmin(values)]\n",
    "    else:\n",
    "        return models[np.argmax(values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b16e93-6185-4162-9dea-7f7d82cabd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\n",
    "        \"RF\",\n",
    "        RandomForestClassifier(),\n",
    "        {\n",
    "            \"max_depth\": [5, 8, 15, 25],\n",
    "            \"max_features\":['log2', 'sqrt']\n",
    "        }\n",
    "    ),\n",
    "    ( \n",
    "        \"LR\",\n",
    "        LogisticRegression(solver='liblinear', max_iter=10000),\n",
    "        {\n",
    "            \"penalty\": ['l1', 'l2'],\n",
    "            \"C\":[0.001,0.01,0.1,1]\n",
    "        }\n",
    "    ),\n",
    "     (\n",
    "         \"Tree\",\n",
    "          DecisionTreeClassifier(),\n",
    "         {\n",
    "            'criterion' : ['gini', 'entropy'],\n",
    "            'max_depth' : [6,8,10,12],\n",
    "            'max_features':[2,4,6,8]\n",
    "\n",
    "         }\n",
    "     )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249489f1-0d45-4333-bb18-cc1c917b1ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10c07e79-42a2-4d0a-8742-914faf60657e",
   "metadata": {},
   "source": [
    "Rodar e guardar o resultado de cada dado separado, modificar amanhã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26321a7f-83a7-4fb6-aa8e-ab8bf5eb8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # função para comprar os modelos\n",
    "# def compara_modelos(datasets:list, estimators:list):\n",
    "#     # compara os modelos por dataset, já tunando os hyperparametros compara o melhor com melhor\n",
    "#     results={}\n",
    "#     for data_name,data_path in datasets:\n",
    "#         vetorizar = TfidfVectorizer(lowercase=False, max_features=200)#mex_features -> 300\n",
    "#         df = pd.read_csv(data_path)\n",
    "#         # dividir dataset para validar o modelo após o treino.\n",
    "#         df_train = df.sample(n=6000)\n",
    "#         bag_of_words_ = vetorizar.fit_transform(df_train[\"text\"])\n",
    "#         X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "#         y = df_train[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "#         for estimator_name, estimator_obj, estimator_params in estimators:\n",
    "\n",
    "#             model_results = cross_score_v2(X,y,data_name,estimator_obj,estimator_name,estimator_params)\n",
    "#             if results:\n",
    "#                 for key, value in model_results.items():\n",
    "#                     results[key] = np.append(results[key], value)\n",
    "#             else:\n",
    "#                 results = model_results\n",
    "                \n",
    "                \n",
    "#     #guarda o resultado da comparação\n",
    "#     df_results = pd.DataFrame(results)\n",
    "#     results = (\n",
    "#         pd\n",
    "#         .DataFrame(df_results)\n",
    "#         .groupby(['model_name'])\n",
    "#         .agg([lambda x: f\"{np.mean(x):.3f} ± {np.std(x):.3f}\"])\n",
    "#         .transpose()\n",
    "#         .reset_index()\n",
    "#         .rename(columns={\"level_0\": \"score\"})\n",
    "#         .drop(columns=\"level_1\")\n",
    "#             # .set_index('score')\n",
    "#     )\n",
    "#     # estiliza o dataframe deixando em cinza o melhor modelo\n",
    "#     time_scores = ['fit_time', 'score_time']\n",
    "#     winner = results.query('score not in @time_scores').apply(get_winner, axis=1).value_counts().index[0]\n",
    "#     results.columns.name = ''\n",
    "#     results = (\n",
    "#         results\n",
    "#         .style\n",
    "#         .hide(axis='index')\n",
    "#         .apply(highlight_max, props='color:white;background-color:gray', axis=1)\n",
    "#     )\n",
    "#     display(results)\n",
    "#     display(Markdown(f'O melhor modelo é o : **{winner}**'))\n",
    "#     # escolhe o melhor modelo\n",
    "#     model_winner = winner.split(\"-\")[0]\n",
    "#     data_winner= winner.split(\"-\")[1]\n",
    "#     model_name, model, model_params  = [foo for foo in estimators if foo[0] == model_winner][0]\n",
    "#     data_name, data_path  = [foo for foo in datasets if foo[0] == data_winner][0]\n",
    "    \n",
    "#     # treina o melhor modelo com todos os textos\n",
    "#     vetorizar = TfidfVectorizer(lowercase=False, max_features=200)\n",
    "#     df = pd.read_csv(data_path)\n",
    "#     df_train = df.sample(n=6000)\n",
    "#     bag_of_words_ = vetorizar.fit_transform(df_train[\"text\"])\n",
    "#     X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "#     y = df_train[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "    \n",
    "#     # tuna os hyperparametros do melhor modelo\n",
    "#     model_BS = BayesSearchCV(model, search_spaces=model_params, scoring='accuracy')\n",
    "#     model_BS.fit(X, y)\n",
    "    \n",
    "#     # Salvando modelo treinado\n",
    "#     path =  f\"../models/model_{model.__class__.__name__}_{data_name}.joblib\"\n",
    "#     joblib.dump(model_BS,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718a741-d900-4408-928a-756816367c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16cdfad9-e6e7-4b0a-954b-e6520d02e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_no_stop = [\n",
    "    (\"no_stop_words_lemma\",\"../data/interim/no_stopWords_lemma.csv\"),\n",
    "    (\"no_stop_words_stemma\",\"../data/interim/no_stopWords_stemma.csv\")\n",
    "]\n",
    "\n",
    "datasets_with_Stop = [\n",
    "    (\"with_stop_words_lemma\",\"../data/interim/with_stopWords_lemma.csv\"),\n",
    "    (\"with_stop_words_stemma\",\"../data/interim/with_stopWords_stemma.csv\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3436f8ac-f0a1-49cf-80f7-1a11eb6575c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compara_modelos(datasets_no_stop, estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96d864ee-dcc0-4b73-a11c-aefa71c3466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compara_modelos(datasets_with_Stop, estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe5ed9-c614-48f2-a7e8-73f09eb7439c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059edeaf-3d93-464e-af57-e126df9fe654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb78b2-9f7b-4711-9130-a5706a4e48ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5011365-9c41-4d3c-8e5b-cc508d503a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf497a6-3e5c-4030-b88c-8015788f2d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e26c5e-c7bf-4c27-9d20-1580ed15b70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f60ca7f-2466-4bea-9008-c3a519671ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38760faa-b079-4791-8271-8cc56a8a77fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eeb0ce1-0fdf-4b5c-af32-8ca7ff8d8831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data name:  no_stop_words_lemma\n",
      "model name:  RF\n",
      "data name:  no_stop_words_lemma\n",
      "model name:  LR\n",
      "data name:  no_stop_words_lemma\n",
      "model name:  Tree\n",
      "data name:  no_stop_words_stemma\n",
      "model name:  RF\n",
      "data name:  no_stop_words_stemma\n",
      "model name:  LR\n",
      "data name:  no_stop_words_stemma\n",
      "model name:  Tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e0afc_row0_col6, #T_e0afc_row1_col6, #T_e0afc_row2_col4, #T_e0afc_row3_col3, #T_e0afc_row4_col3 {\n",
       "  color: white;\n",
       "  background-color: gray;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e0afc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_e0afc_level0_col0\" class=\"col_heading level0 col0\" >score</th>\n",
       "      <th id=\"T_e0afc_level0_col1\" class=\"col_heading level0 col1\" >LR-no_stop_words_lemma</th>\n",
       "      <th id=\"T_e0afc_level0_col2\" class=\"col_heading level0 col2\" >LR-no_stop_words_stemma</th>\n",
       "      <th id=\"T_e0afc_level0_col3\" class=\"col_heading level0 col3\" >RF-no_stop_words_lemma</th>\n",
       "      <th id=\"T_e0afc_level0_col4\" class=\"col_heading level0 col4\" >RF-no_stop_words_stemma</th>\n",
       "      <th id=\"T_e0afc_level0_col5\" class=\"col_heading level0 col5\" >Tree-no_stop_words_lemma</th>\n",
       "      <th id=\"T_e0afc_level0_col6\" class=\"col_heading level0 col6\" >Tree-no_stop_words_stemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_e0afc_row0_col0\" class=\"data row0 col0\" >fit_time</td>\n",
       "      <td id=\"T_e0afc_row0_col1\" class=\"data row0 col1\" >105.748 ± 2.230</td>\n",
       "      <td id=\"T_e0afc_row0_col2\" class=\"data row0 col2\" >92.979 ± 6.418</td>\n",
       "      <td id=\"T_e0afc_row0_col3\" class=\"data row0 col3\" >300.000 ± 12.951</td>\n",
       "      <td id=\"T_e0afc_row0_col4\" class=\"data row0 col4\" >289.635 ± 4.342</td>\n",
       "      <td id=\"T_e0afc_row0_col5\" class=\"data row0 col5\" >102.701 ± 12.600</td>\n",
       "      <td id=\"T_e0afc_row0_col6\" class=\"data row0 col6\" >83.204 ± 2.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e0afc_row1_col0\" class=\"data row1 col0\" >score_time</td>\n",
       "      <td id=\"T_e0afc_row1_col1\" class=\"data row1 col1\" >0.011 ± 0.004</td>\n",
       "      <td id=\"T_e0afc_row1_col2\" class=\"data row1 col2\" >0.007 ± 0.001</td>\n",
       "      <td id=\"T_e0afc_row1_col3\" class=\"data row1 col3\" >0.026 ± 0.003</td>\n",
       "      <td id=\"T_e0afc_row1_col4\" class=\"data row1 col4\" >0.030 ± 0.008</td>\n",
       "      <td id=\"T_e0afc_row1_col5\" class=\"data row1 col5\" >0.006 ± 0.001</td>\n",
       "      <td id=\"T_e0afc_row1_col6\" class=\"data row1 col6\" >0.005 ± 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e0afc_row2_col0\" class=\"data row2 col0\" >test_recall</td>\n",
       "      <td id=\"T_e0afc_row2_col1\" class=\"data row2 col1\" >0.934 ± 0.007</td>\n",
       "      <td id=\"T_e0afc_row2_col2\" class=\"data row2 col2\" >0.941 ± 0.013</td>\n",
       "      <td id=\"T_e0afc_row2_col3\" class=\"data row2 col3\" >0.953 ± 0.011</td>\n",
       "      <td id=\"T_e0afc_row2_col4\" class=\"data row2 col4\" >0.955 ± 0.005</td>\n",
       "      <td id=\"T_e0afc_row2_col5\" class=\"data row2 col5\" >0.827 ± 0.021</td>\n",
       "      <td id=\"T_e0afc_row2_col6\" class=\"data row2 col6\" >0.849 ± 0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e0afc_row3_col0\" class=\"data row3 col0\" >test_accuracy</td>\n",
       "      <td id=\"T_e0afc_row3_col1\" class=\"data row3 col1\" >0.934 ± 0.008</td>\n",
       "      <td id=\"T_e0afc_row3_col2\" class=\"data row3 col2\" >0.939 ± 0.014</td>\n",
       "      <td id=\"T_e0afc_row3_col3\" class=\"data row3 col3\" >0.951 ± 0.008</td>\n",
       "      <td id=\"T_e0afc_row3_col4\" class=\"data row3 col4\" >0.950 ± 0.001</td>\n",
       "      <td id=\"T_e0afc_row3_col5\" class=\"data row3 col5\" >0.853 ± 0.014</td>\n",
       "      <td id=\"T_e0afc_row3_col6\" class=\"data row3 col6\" >0.874 ± 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e0afc_row4_col0\" class=\"data row4 col0\" >test_f1</td>\n",
       "      <td id=\"T_e0afc_row4_col1\" class=\"data row4 col1\" >0.935 ± 0.007</td>\n",
       "      <td id=\"T_e0afc_row4_col2\" class=\"data row4 col2\" >0.939 ± 0.015</td>\n",
       "      <td id=\"T_e0afc_row4_col3\" class=\"data row4 col3\" >0.951 ± 0.007</td>\n",
       "      <td id=\"T_e0afc_row4_col4\" class=\"data row4 col4\" >0.951 ± 0.003</td>\n",
       "      <td id=\"T_e0afc_row4_col5\" class=\"data row4 col5\" >0.851 ± 0.014</td>\n",
       "      <td id=\"T_e0afc_row4_col6\" class=\"data row4 col6\" >0.872 ± 0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4c7bf92610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "O melhor modelo é o : **RF-no_stop_words_lemma**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['../models/model_RandomForestClassifier_no_stop_words_lemma.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results={}\n",
    "for data_name,data_path in datasets_no_stop:\n",
    "    vetorizar = TfidfVectorizer(lowercase=False, max_features=200)#mex_features -> 300\n",
    "    df = pd.read_csv(data_path)\n",
    "    # separando uma parte para  teste\n",
    "    df_train = df.sample(n=6000)\n",
    "    bag_of_words_ = vetorizar.fit_transform(df_train[\"text\"])\n",
    "    X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "    y = df_train[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "    for estimator_name, estimator_obj, estimator_params in estimators:\n",
    "\n",
    "        model_results = cross_score_v2(X,y,data_name,estimator_obj,estimator_name,estimator_params)\n",
    "        if results:\n",
    "            for key, value in model_results.items():\n",
    "                results[key] = np.append(results[key], value)\n",
    "        else:\n",
    "            results = model_results\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "results = (\n",
    "    pd\n",
    "    .DataFrame(df_results)\n",
    "    .groupby(['model_name'])\n",
    "    .agg([lambda x: f\"{np.mean(x):.3f} ± {np.std(x):.3f}\"])#\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"score\"})\n",
    "    .drop(columns=\"level_1\")\n",
    "    # .set_index('score')\n",
    ")\n",
    "time_scores = ['fit_time', 'score_time']\n",
    "winner = results.query('score not in @time_scores').apply(get_winner, axis=1).value_counts().index[0]\n",
    "results.columns.name = ''\n",
    "results = (\n",
    "    results\n",
    "    .style\n",
    "    .hide(axis='index')\n",
    "    .apply(highlight_max, props='color:white;background-color:gray', axis=1)\n",
    ")\n",
    "display(results)\n",
    "display(Markdown(f'O melhor modelo é o : **{winner}**'))\n",
    "\n",
    "\n",
    "\n",
    "# Realizando treino do modelo completo\n",
    "model_winner = winner.split(\"-\")[0]\n",
    "data_winner= winner.split(\"-\")[1]\n",
    "model_name, model, model_params  = [foo for foo in estimators if foo[0] == model_winner][0]\n",
    "data_name, data_path  = [foo for foo in datasets_no_stop if foo[0] == data_winner][0]\n",
    "\n",
    "vetorizar = TfidfVectorizer(lowercase=False, max_features=50)\n",
    "df = pd.read_csv(data_path)\n",
    "#df_train = df.sample(n=6000)\n",
    "bag_of_words_ = vetorizar.fit_transform(df[\"text\"])\n",
    "X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "y = df[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "\n",
    "model_Bs = BayesSearchCV(model, search_spaces=model_params, scoring='accuracy')\n",
    "model_Bs.fit(X, y)\n",
    "\n",
    "\n",
    "# Salvando modelo treinado\n",
    "path =  f\"../models/model_{model.__class__.__name__}_{data_name}.joblib\"\n",
    "joblib.dump(model_Bs,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb4326e5-ec4e-4e42-a7bb-3c22316a83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data name:  with_stop_words_lemma\n",
      "model name:  RF\n",
      "data name:  with_stop_words_lemma\n",
      "model name:  LR\n",
      "data name:  with_stop_words_lemma\n",
      "model name:  Tree\n",
      "data name:  with_stop_words_stemma\n",
      "model name:  RF\n",
      "data name:  with_stop_words_stemma\n",
      "model name:  LR\n",
      "data name:  with_stop_words_stemma\n",
      "model name:  Tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_162d8_row0_col5, #T_162d8_row1_col5, #T_162d8_row2_col3, #T_162d8_row3_col3, #T_162d8_row4_col3 {\n",
       "  color: white;\n",
       "  background-color: gray;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_162d8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_162d8_level0_col0\" class=\"col_heading level0 col0\" >score</th>\n",
       "      <th id=\"T_162d8_level0_col1\" class=\"col_heading level0 col1\" >LR-with_stop_words_lemma</th>\n",
       "      <th id=\"T_162d8_level0_col2\" class=\"col_heading level0 col2\" >LR-with_stop_words_stemma</th>\n",
       "      <th id=\"T_162d8_level0_col3\" class=\"col_heading level0 col3\" >RF-with_stop_words_lemma</th>\n",
       "      <th id=\"T_162d8_level0_col4\" class=\"col_heading level0 col4\" >RF-with_stop_words_stemma</th>\n",
       "      <th id=\"T_162d8_level0_col5\" class=\"col_heading level0 col5\" >Tree-with_stop_words_lemma</th>\n",
       "      <th id=\"T_162d8_level0_col6\" class=\"col_heading level0 col6\" >Tree-with_stop_words_stemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_162d8_row0_col0\" class=\"data row0 col0\" >fit_time</td>\n",
       "      <td id=\"T_162d8_row0_col1\" class=\"data row0 col1\" >207.587 ± 8.330</td>\n",
       "      <td id=\"T_162d8_row0_col2\" class=\"data row0 col2\" >141.814 ± 5.196</td>\n",
       "      <td id=\"T_162d8_row0_col3\" class=\"data row0 col3\" >333.535 ± 18.236</td>\n",
       "      <td id=\"T_162d8_row0_col4\" class=\"data row0 col4\" >370.342 ± 22.440</td>\n",
       "      <td id=\"T_162d8_row0_col5\" class=\"data row0 col5\" >92.040 ± 1.586</td>\n",
       "      <td id=\"T_162d8_row0_col6\" class=\"data row0 col6\" >93.503 ± 3.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_162d8_row1_col0\" class=\"data row1 col0\" >score_time</td>\n",
       "      <td id=\"T_162d8_row1_col1\" class=\"data row1 col1\" >0.007 ± 0.001</td>\n",
       "      <td id=\"T_162d8_row1_col2\" class=\"data row1 col2\" >0.006 ± 0.000</td>\n",
       "      <td id=\"T_162d8_row1_col3\" class=\"data row1 col3\" >0.024 ± 0.002</td>\n",
       "      <td id=\"T_162d8_row1_col4\" class=\"data row1 col4\" >0.026 ± 0.000</td>\n",
       "      <td id=\"T_162d8_row1_col5\" class=\"data row1 col5\" >0.005 ± 0.001</td>\n",
       "      <td id=\"T_162d8_row1_col6\" class=\"data row1 col6\" >0.005 ± 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_162d8_row2_col0\" class=\"data row2 col0\" >test_recall</td>\n",
       "      <td id=\"T_162d8_row2_col1\" class=\"data row2 col1\" >0.939 ± 0.011</td>\n",
       "      <td id=\"T_162d8_row2_col2\" class=\"data row2 col2\" >0.941 ± 0.007</td>\n",
       "      <td id=\"T_162d8_row2_col3\" class=\"data row2 col3\" >0.946 ± 0.008</td>\n",
       "      <td id=\"T_162d8_row2_col4\" class=\"data row2 col4\" >0.941 ± 0.007</td>\n",
       "      <td id=\"T_162d8_row2_col5\" class=\"data row2 col5\" >0.883 ± 0.014</td>\n",
       "      <td id=\"T_162d8_row2_col6\" class=\"data row2 col6\" >0.838 ± 0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_162d8_row3_col0\" class=\"data row3 col0\" >test_accuracy</td>\n",
       "      <td id=\"T_162d8_row3_col1\" class=\"data row3 col1\" >0.922 ± 0.002</td>\n",
       "      <td id=\"T_162d8_row3_col2\" class=\"data row3 col2\" >0.930 ± 0.003</td>\n",
       "      <td id=\"T_162d8_row3_col3\" class=\"data row3 col3\" >0.949 ± 0.001</td>\n",
       "      <td id=\"T_162d8_row3_col4\" class=\"data row3 col4\" >0.943 ± 0.004</td>\n",
       "      <td id=\"T_162d8_row3_col5\" class=\"data row3 col5\" >0.880 ± 0.006</td>\n",
       "      <td id=\"T_162d8_row3_col6\" class=\"data row3 col6\" >0.857 ± 0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_162d8_row4_col0\" class=\"data row4 col0\" >test_f1</td>\n",
       "      <td id=\"T_162d8_row4_col1\" class=\"data row4 col1\" >0.924 ± 0.001</td>\n",
       "      <td id=\"T_162d8_row4_col2\" class=\"data row4 col2\" >0.932 ± 0.003</td>\n",
       "      <td id=\"T_162d8_row4_col3\" class=\"data row4 col3\" >0.950 ± 0.001</td>\n",
       "      <td id=\"T_162d8_row4_col4\" class=\"data row4 col4\" >0.944 ± 0.004</td>\n",
       "      <td id=\"T_162d8_row4_col5\" class=\"data row4 col5\" >0.881 ± 0.008</td>\n",
       "      <td id=\"T_162d8_row4_col6\" class=\"data row4 col6\" >0.857 ± 0.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4c7bc97b80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "O melhor modelo é o : **RF-with_stop_words_lemma**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m data_winner\u001b[38;5;241m=\u001b[39m winner\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     51\u001b[0m model_name, model, model_params  \u001b[38;5;241m=\u001b[39m [foo \u001b[38;5;28;01mfor\u001b[39;00m foo \u001b[38;5;129;01min\u001b[39;00m estimators \u001b[38;5;28;01mif\u001b[39;00m foo[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m model_winner][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 52\u001b[0m data_name, data_path  \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mfoo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfoo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdatasets_no_stop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfoo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_winner\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     54\u001b[0m vetorizar \u001b[38;5;241m=\u001b[39m TfidfVectorizer(lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     55\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for data_name,data_path in datasets_with_Stop:\n",
    "    vetorizar = TfidfVectorizer(lowercase=False, max_features=200)#mex_features -> 300\n",
    "    df = pd.read_csv(data_path)\n",
    "    df_train = df.sample(n=6000)\n",
    "    bag_of_words_ = vetorizar.fit_transform(df_train[\"text\"])\n",
    "    X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "    y = df_train[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "    for estimator_name, estimator_obj, estimator_params in estimators:\n",
    "\n",
    "        model_results = cross_score_v2(X,y,data_name,estimator_obj,estimator_name,estimator_params)\n",
    "        if results:\n",
    "            for key, value in model_results.items():\n",
    "                results[key] = np.append(results[key], value)\n",
    "        else:\n",
    "            results = model_results\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "results = (\n",
    "    pd\n",
    "    .DataFrame(df_results)\n",
    "    .groupby(['model_name'])\n",
    "    .agg([lambda x: f\"{np.mean(x):.3f} ± {np.std(x):.3f}\"])#\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"score\"})\n",
    "    .drop(columns=\"level_1\")\n",
    "    # .set_index('score')\n",
    ")\n",
    "time_scores = ['fit_time', 'score_time']\n",
    "winner = results.query('score not in @time_scores').apply(get_winner, axis=1).value_counts().index[0]\n",
    "results.columns.name = ''\n",
    "results = (\n",
    "    results\n",
    "    .style\n",
    "    .hide(axis='index')\n",
    "    .apply(highlight_max, props='color:white;background-color:gray', axis=1)\n",
    ")\n",
    "display(results)\n",
    "display(Markdown(f'O melhor modelo é o : **{winner}**'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69516d91-11af-448a-a6d1-89728a22c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/model_RandomForestClassifier_with_stop_words_lemma.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizando treino do modelo completo\n",
    "model_winner = winner.split(\"-\")[0]\n",
    "data_winner= winner.split(\"-\")[1]\n",
    "model_name, model, model_params  = [foo for foo in estimators if foo[0] == model_winner][0]\n",
    "data_name, data_path  = [foo for foo in datasets_with_Stop if foo[0] == data_winner][0]\n",
    "\n",
    "vetorizar = TfidfVectorizer(lowercase=False, max_features=50)\n",
    "df = pd.read_csv(data_path)\n",
    "bag_of_words_ = vetorizar.fit_transform(df[\"text\"])\n",
    "X = pd.DataFrame(bag_of_words_.toarray(),columns=vetorizar.get_feature_names_out())\n",
    "y = df[\"label\"].replace({\"true\":1,\"fake\":0}).to_numpy().ravel()\n",
    "\n",
    "model_BS =  BayesSearchCV(model, search_spaces=model_params, scoring='accuracy')\n",
    "model_BS.fit(X, y)\n",
    "\n",
    "\n",
    "# Salvando modelo treinado\n",
    "path =  f\"../models/model_{model.__class__.__name__}_{data_name}.joblib\"\n",
    "joblib.dump(model_BS,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ca7d1-7a3d-44ab-945a-a759d890dd41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
